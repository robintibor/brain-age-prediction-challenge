{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11e4dc71-dfc8-4f29-941c-c5156bc23cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63200b51-dcec-418c-ba50-3e8884fd6b89",
   "metadata": {},
   "source": [
    "## Data preparation First Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb0dabd-8048-445c-bde0-e5cb95fc13cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import mne\n",
    "from joblib import Parallel, delayed\n",
    "sfreq = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78c5db75-1b74-4cde-933b-b0ce96da796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_jobs = 30\n",
    "\n",
    "files = sorted(glob.glob('/work/dlclarge2/schirrmr-eeg-age-competition/training/*_raw.fif.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c2ee93-efa8-4516-853e-9c1247d89e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do(file, sfreq):\n",
    "    raw = mne.io.read_raw_fif(file, verbose='error')\n",
    "    raw.resample(sfreq=sfreq)\n",
    "    raw.save(file.replace('_raw.fif.gz', f'_{sfreq}_hz_raw.fif.gz'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309867df-3423-446b-8ca5-3d3b3924a5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in tqdm(files):\n",
    "    do(f, sfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a0d57-01f6-48c6-a851-95744767fe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data https://filesender.renater.fr/?s=download&token=e1de0ec4-09bc-4194-b85b-59830cb04af3\n",
    "# download test data from https://codalab.lisn.upsaclay.fr/competitions/8336\n",
    "\n",
    "# Path to training data\n",
    "train_path = \"/work/dlclarge2/schirrmr-eeg-age-competition/lukas/data/training/\"\n",
    "# Path to testing data (public test set)\n",
    "test_path = \"/work/dlclarge2/schirrmr-eeg-age-competition/lukas/data/testing/\"\n",
    "train_subj = 1200  # use 10 instead of 1200 training subjects, for demonstration purpose\n",
    "test_subj = 400  # use 10 instead of 400 testing subjects, for demonstration purpose\n",
    "\n",
    "train_raws, test_raws = {}, {}\n",
    "for condition in [\"EC\", \"EO\"]:\n",
    "    train_raws[condition] = []\n",
    "    test_raws[condition] = []\n",
    "    train_subjs = list(range(1, train_subj + 1))\n",
    "    for s in tqdm(train_subjs):\n",
    "        fname = f\"subj{s:04}_{condition}_{sfreq}_hz_raw.fif.gz\"\n",
    "        raw = mne.io.read_raw(train_path + fname, preload=False, verbose='error')\n",
    "        \n",
    "        train_raws[condition].append(raw)\n",
    "    test_subjs = list(range(1201, 1201 + test_subj))\n",
    "    for s in tqdm(test_subjs):\n",
    "        fname = f\"subj{s:04}_{condition}_{sfreq}_hz_raw.fif.gz\"\n",
    "        raw = mne.io.read_raw(test_path + fname, preload=False, verbose='error')\n",
    "        test_raws[condition].append(raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313b3a8e-52e9-4e8a-b2b8-0b82a552fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba2f09c-91ac-4de4-8c45-c9353fb8a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(train_path + \"train_subjects.csv\", index_col=0)\n",
    "meta = pd.concat([meta, meta])\n",
    "meta['condition'] = len(train_raws['EC']) * ['EC'] + len(train_raws['EO']) * ['EO']\n",
    "train_raws = train_raws['EC'] + train_raws['EO']\n",
    "len(train_raws), len(meta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ad1860-a6cb-4814-9f0e-1bee5c208d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_meta = pd.DataFrame({'condition': len(test_raws['EC']) * ['EC'] + len(test_raws['EO']) * ['EO']})\n",
    "test_raws = test_raws['EC'] + test_raws['EO']\n",
    "len(test_raws), len(test_meta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1981c345-5aed-457c-bab5-325ffe1a5aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datasets import BaseConcatDataset, BaseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b25009-e192-45f8-8004-c0f4aec315be",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = 'age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77a6494-718e-49e6-8262-ab98ac0de318",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = BaseConcatDataset([\n",
    "    BaseDataset(raw, target_name=target_name) for raw in train_raws\n",
    "])\n",
    "meta['subject'] = meta['id']\n",
    "train.set_description(meta)\n",
    "train.set_description({'path': [ds.raw.filenames[0] for ds in train.datasets]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8ea732-d9b5-4403-bdaf-d0a1ac9faa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(train_path + f'train_{sfreq}_hz.pkl', 'wb') as f:\n",
    "    pickle.dump(train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b18834-d486-4cde-a482-4e4b39e1e7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = BaseConcatDataset([\n",
    "    BaseDataset(raw) for raw in test_raws\n",
    "])\n",
    "test_meta['subject'] = test_subjs + test_subjs\n",
    "test.set_description(test_meta)\n",
    "test.set_description({'path': [ds.raw.filenames[0] for ds in test.datasets]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f6b0a2-bda7-4dbd-a2e2-aab1e87341ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_path + f'test_{sfreq}_hz.pkl', 'wb') as f:\n",
    "    pickle.dump(test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6aa787-6517-4f8d-81c9-63cab70a0402",
   "metadata": {},
   "source": [
    "## Data Preparation Second Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ba0ac6-3da3-4786-a985-8055e1cf73b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_tueg import decode_tueg\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "exp_date = datetime.datetime.now().isoformat()\n",
    "\n",
    "base_dir = '/work/dlclarge2/schirrmr-eeg-age-competition/results/'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "params = {\n",
    "    'model_name': ['deep'],  # 'shallow', 'deep', 'tcn'\n",
    "    'subset': ['normal'],  # 'normal', 'abnormal', 'mixed'\n",
    "    'target_name': ['age'],  # age, gender, pathological, age_clf\n",
    "\n",
    "    'valid_set_i': [0],  # 0, 1, 2, 3, 4\n",
    "    'n_epochs': [35],  # 35, 105, 210\n",
    "    'n_restarts': [0],  # 0, 2, 5\n",
    "    'augment': ['0'],  # dropout, flipfb, fliplr, noise, mask, reverse, shuffle, sign, random, identity, '0'\n",
    "    'fast_mode': [1],\n",
    "    'loss': ['mae'],  # mse, mae, log_cosh, huber, nll\n",
    "\n",
    "    'condition': ['all'],  # 'all', 'EC', 'EO', TODO: implement using both, prevent subject leakage in both sets\n",
    "    'n_train_recordings': [-1],  # -1: None\n",
    "    'tmax': [-1],  # 4*60done, 6*60done, 11*60done, -1,  00# -1: None\n",
    "    'min_age': [-1],\n",
    "    'max_age': [-1],\n",
    "    # 'data_path': ['/home/jovyan/mne_data/TUH_PRE/tuh_eeg_abnormal/v2.0.0/edf/'],\n",
    "    'data_path': ['/work/dlclarge2/schirrmr-eeg-age-competition/lukas/data/training/'],\n",
    "    'squash_outs': [1],  # force output to be in [0, 1] through sigmoid\n",
    "\n",
    "    'final_eval': [0],\n",
    "    'debug': [1],\n",
    "    'seed': [20221116],  # default 20220429\n",
    "    'date': [exp_date],  # sometimes, need to restart some of the cv runs, due to cluster failure. do not reset exp date then\n",
    "    'intuitive_training_scores': [1],  # 1: add slow callbacks that track age decodnig loss intuitively as mae\n",
    "    'out_dir': [os.path.join(base_dir, 'competition/results/')],\n",
    "    'n_jobs': [2],  # faster than 1, 3, and 4 on tmax=2*60, n_recordings=-1, subset=normal, n_epochs=5, preload=0\n",
    "    'preload': [1],\n",
    "\n",
    "    'batch_size': [64],  # 64. does CroppedTrialEpochStoring increase GPU memory consumption? 256 works fine in notebook but fails as pipeline. 128 works with shallow fails with deep\n",
    "    'tmin': [-1],\n",
    "    'standardize_data': [0],  # TODO: needs to be implemented. sclaing to microvolts is done anyways\n",
    "    'standardize_targets': [1],\n",
    "    'window_size_samples': [1500],  # EC condition is ~40s, EO only ~20s\n",
    "    'shuffle_data_before_split': [0],\n",
    "}\n",
    "\n",
    "\n",
    "params = {k: params[k][0] for k in params}\n",
    "params['config'] = pd.Series(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d908df2-f5b9-402b-896e-33f8f78db287",
   "metadata": {},
   "outputs": [],
   "source": [
    "locals().update(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246d7604-9aec-4536-8921-3915e05e91ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_tueg import add_file_logger, check_input_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703d9a33-8344-4c24-bd80-9d9ee58866a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "import logging\n",
    "import warnings\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "from io import StringIO as StringBuffer\n",
    "\n",
    "import mne\n",
    "mne.set_log_level('ERROR')\n",
    "#mne.set_config(\"MNE_LOGGING_LEVEL\", \"ERROR\")\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_color_codes('deep')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "plt.set_loglevel('ERROR')\n",
    "from sklearn.metrics import mean_absolute_error, balanced_accuracy_score, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from skorch.helper import predefined_split\n",
    "from skorch.callbacks import LRScheduler, Checkpoint, TrainEndCheckpoint, ProgressBar, BatchScoring\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from skorch.utils import valid_loss_score, noop\n",
    "\n",
    "from braindecode.datasets import BaseDataset, BaseConcatDataset\n",
    "from braindecode.datasets.tuh import TUHAbnormal\n",
    "from braindecode.preprocessing import Preprocessor, preprocess\n",
    "from braindecode.preprocessing.windowers import create_fixed_length_windows\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet, to_dense_prediction_model, Deep4Net, TCN\n",
    "from braindecode.models.modules import Expression\n",
    "from braindecode.regressor import EEGRegressor\n",
    "from braindecode.classifier import EEGClassifier\n",
    "from braindecode.training import CroppedLoss, CroppedTrialEpochScoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfb6c28-1d6e-4669-abf7-1d6de33b3e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s %(levelname)s : %(message)s\",\n",
    "    level=logging.DEBUG,\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(\"DEBUG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4399f3a-b59e-4d74-a51a-a46b84428f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = os.path.join(out_dir, date, str(seed), str(valid_set_i))\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "else:\n",
    "    raise RuntimeError(f'Directory already exists {out_dir}')\n",
    "add_file_logger(\n",
    "    logger=logger,\n",
    "    out_dir=out_dir,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"'pathological' not in description.\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"torch.backends.cudnn.benchmark was set to True which\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"You are using an callback that overrides on_batch_begin or on_batc\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"This function was designed to predict trials from cropped datasets\")\n",
    "#warnings.filterwarnings(\"ignore\", message=\"UserWarning: y_pred contains classes not in y_true\")\n",
    "\n",
    "check_input_args(\n",
    "    batch_size, condition, config, data_path, debug, final_eval, intuitive_training_scores,\n",
    "    max_age, min_age, model_name, n_epochs, n_jobs, n_restarts, n_train_recordings, \n",
    "    out_dir, preload, seed, shuffle_data_before_split, squash_outs, \n",
    "    standardize_data, standardize_targets, subset, target_name, tmax, tmin, \n",
    "    valid_set_i, window_size_samples, augment, loss, logger,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a361fa05-ca05-4d37-b162-a20bdc1075f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_capture_string = get_log_capturer(logger, debug)\n",
    "level = logging.DEBUG if debug == 1 else logging.INFO\n",
    "logger.setLevel(level)\n",
    "logger.info(f'\\n{config.sort_index()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df5ec69-c5fa-4b1c-892d-d15ee72385bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if GPU is available, if True chooses to use it\n",
    "cuda = torch.cuda.is_available()\n",
    "if not cuda:\n",
    "    raise RuntimeError('no gpu found')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "logger.debug(f\"cuda: {cuda}\")\n",
    "cropped = True\n",
    "logger.debug(f\"cropped: {cropped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ded4491-d3ef-4b01-9ca4-b1f34696012b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_tueg import get_competition_datasets\n",
    "from decode_tueg import test_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb736e8f-8a04-44b4-852d-570c97d81a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuabn_train, tuabn_valid, mapping, valid_rest, valid_rest_name = get_competition_datasets(\n",
    "            data_path,\n",
    "            target_name,\n",
    "            subset,\n",
    "            n_train_recordings,\n",
    "            tmin,\n",
    "            tmax,\n",
    "            n_jobs,\n",
    "            final_eval,\n",
    "            valid_set_i,\n",
    "            seed,\n",
    "            min_age,\n",
    "            max_age,\n",
    "            condition,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b12a94b-8227-47e3-8d0d-e2768baef0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_tueg import save_input\n",
    "save_input(\n",
    "        config,\n",
    "        out_dir,\n",
    "        tuabn_train.description,\n",
    "        tuabn_valid.description,\n",
    "        test_name(final_eval),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed047e3-bcce-4d21-a215-b8fc6623cb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_tueg import get_model\n",
    "\n",
    "\n",
    "ch_names = tuabn_train.datasets[0].raw.ch_names\n",
    "sfreq = tuabn_train.datasets[0].raw.info['sfreq']\n",
    "n_channels = len(ch_names)\n",
    "model, lr, weight_decay = get_model(\n",
    "    n_channels,\n",
    "    seed,\n",
    "    cuda,\n",
    "    target_name,\n",
    "    model_name,\n",
    "    cropped,\n",
    "    window_size_samples,\n",
    "    squash_outs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07324464-2672-4cd0-b19a-e85eccfe1b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_tueg import create_windows\n",
    "from decode_tueg import get_n_preds_per_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bac86b-60bb-497b-b14f-21f4c316b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_preds_per_input = get_n_preds_per_input(\n",
    "    model,\n",
    "    n_channels,\n",
    "    window_size_samples,\n",
    ")\n",
    "tuabn_train, tuabn_valid = create_windows(\n",
    "    mapping, \n",
    "    tuabn_train,\n",
    "    tuabn_valid,\n",
    "    window_size_samples,\n",
    "    n_jobs,\n",
    "    preload,\n",
    "    n_preds_per_input,\n",
    "    test_name(final_eval),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d32aeb-0dd6-487d-b566-541adc381bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_tueg import standardize\n",
    "\n",
    "\n",
    "tuabn_train, tuabn_valid = standardize(\n",
    "    standardize_data, \n",
    "    standardize_targets,\n",
    "    tuabn_train,\n",
    "    tuabn_valid,\n",
    "    target_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6d6b20-f94e-41b0-85d4-44e3893dae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tuabn_train, open('tuabn_train.pkl', 'wb'))\n",
    "pickle.dump(tuabn_valid, open('tuabn_valid.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52da3337-b3ee-40d3-b213-c0c00985f0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path.replace('training', 'testing'), f'test_{int(sfreq):d}_hz.pkl'), 'rb') as f:\n",
    "    tuabn_eval = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ea8986-087d-4a58-a824-8584c7b60d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode_tueg import _create_windows\n",
    "tuabn_eval = _create_windows(\n",
    "                tuabn_eval,\n",
    "                window_size_samples,\n",
    "                n_jobs, \n",
    "                preload,\n",
    "                n_preds_per_input,\n",
    "                mapping,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d5323a-f7c7-48ba-aaba-9ae86eeb8a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tuabn_eval, open('tuabn_eval.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
